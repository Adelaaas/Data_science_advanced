{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03. Введение в NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SIJ0ctIYKFeB",
        "8nFRLpcRIr9E"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "POEyUSLO_Gac",
        "outputId": "16df6c21-bd73-44bf-c0e0-bbdde8130449"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2d3e24e3-9ee0-4503-a98f-e23879cda1b6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2d3e24e3-9ee0-4503-a98f-e23879cda1b6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving News_dataset.csv to News_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "FcFC4xOt5dp_",
        "outputId": "9758510a-c2c0-4968-f7b2-89d9a9e0ccda"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"News_dataset.csv\", sep=';')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Name</th>\n",
              "      <th>Content</th>\n",
              "      <th>Category</th>\n",
              "      <th>Complete_Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.txt</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "      <td>001.txt-business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.txt</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "      <td>002.txt-business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.txt</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>business</td>\n",
              "      <td>003.txt-business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.txt</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>business</td>\n",
              "      <td>004.txt-business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.txt</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>business</td>\n",
              "      <td>005.txt-business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  File_Name  ... Complete_Filename\n",
              "0   001.txt  ...  001.txt-business\n",
              "1   002.txt  ...  002.txt-business\n",
              "2   003.txt  ...  003.txt-business\n",
              "3   004.txt  ...  004.txt-business\n",
              "4   005.txt  ...  005.txt-business\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYbbJx1_BInO"
      },
      "source": [
        "# Исследование данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F56UQA0BLk4"
      },
      "source": [
        "- размерность данных\n",
        "- пропущенные значения\n",
        "- типы данных в датасете\n",
        "- количество и баланс классов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s5fs8TJBL2V",
        "outputId": "0da87f91-b45c-4ca5-cc70-53501bd88b10"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2225, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZpyrevpBN0y",
        "outputId": "a771a324-38f9-47b5-adf9-0f5f286c623a"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   File_Name          2225 non-null   object\n",
            " 1   Content            2225 non-null   object\n",
            " 2   Category           2225 non-null   object\n",
            " 3   Complete_Filename  2225 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 69.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocUekkQDBUic",
        "outputId": "53e07564-aaa9-43b3-e503-91fedd389cf0"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "File_Name            0\n",
              "Content              0\n",
              "Category             0\n",
              "Complete_Filename    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiJUPcaqBY4w",
        "outputId": "50fd91d6-7f65-4aff-a57d-9c3374069572"
      },
      "source": [
        "df['Category'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkyrIECHU8Nt",
        "outputId": "c9d84682-edf1-41ed-c374-babfab55f73e"
      },
      "source": [
        "df['Category'].value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3kllk4__jFW"
      },
      "source": [
        "# Обработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O165evV_ko0"
      },
      "source": [
        "Предварительная обработка и очистка текстовых данных\n",
        "Любой рабочий процесс анализа данных начинается с их загрузки. Далее мы должны пропустить их через конвейер (pipeline) предобработки:\n",
        "\n",
        "- удаление знаков препинания, лишних и спец символов\n",
        "- приведение к одному регистру\n",
        "- токенизировать текст – разбить текст на предложения, слова и другие единицы;\n",
        "- удалить стоп-слова;\n",
        "- привести слова к нормальной форме;\n",
        "- векторизовать тексты – сделать числовые представления текстов для их дальнейшей обработки классификатором.\n",
        "\n",
        "Все эти шаги служат для уменьшения шума, присущего любому обычному тексту, и повышения точности результатов классификатора. Для решения указанных задач есть несколько отличных библиотек, например, NLTK, TextBlob и spaCy. Последнюю мы и будем применять в этом руководстве."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "ngIOF_8hA80P",
        "outputId": "972007ab-aaa0-40f6-a411-5a8f01d8e4c4"
      },
      "source": [
        "df.loc[1]['Content']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman\\'s taking a much more sanguine view on the current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\\n\\nWorries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged to the dollar and the US currency\\'s sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gl-IarFIlKY"
      },
      "source": [
        "## Работа со специальными символами и знаками пунктуации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYYnQO0-Fyax"
      },
      "source": [
        "Посмотрев на один из текстов мы можем увидеть много специальных символов:\n",
        "\n",
        "- \\r\n",
        "- \\n - переход на новую строку\n",
        "- \\ before possessive pronouns (government's = government\\'s)\n",
        "- \\ before possessive pronouns 2 (Yukos' = Yukos\\')\n",
        "- \" when quoting text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "AGA1LyW8FeOM",
        "outputId": "97421237-bfe0-422d-f7d3-5a5f79bb8fbd"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Name</th>\n",
              "      <th>Content</th>\n",
              "      <th>Category</th>\n",
              "      <th>Complete_Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.txt</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "      <td>001.txt-business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.txt</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "      <td>002.txt-business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  File_Name  ... Complete_Filename\n",
              "0   001.txt  ...  001.txt-business\n",
              "1   002.txt  ...  002.txt-business\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "yVIsZBW2GEmL",
        "outputId": "44b48af8-215c-474f-c1ed-cb817c1e5c63"
      },
      "source": [
        "# \\r and \\n\n",
        "\n",
        "df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
        "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
        "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Name</th>\n",
              "      <th>Content</th>\n",
              "      <th>Category</th>\n",
              "      <th>Complete_Filename</th>\n",
              "      <th>Content_Parsed_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.txt</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "      <td>001.txt-business</td>\n",
              "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.txt</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "      <td>002.txt-business</td>\n",
              "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.txt</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>business</td>\n",
              "      <td>003.txt-business</td>\n",
              "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.txt</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>business</td>\n",
              "      <td>004.txt-business</td>\n",
              "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.txt</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>business</td>\n",
              "      <td>005.txt-business</td>\n",
              "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>397.txt</td>\n",
              "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
              "      <td>tech</td>\n",
              "      <td>397.txt-tech</td>\n",
              "      <td>BT program to beat dialler scams  BT is introd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>398.txt</td>\n",
              "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
              "      <td>tech</td>\n",
              "      <td>398.txt-tech</td>\n",
              "      <td>Spam e-mails tempt net shoppers  Computer user...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>399.txt</td>\n",
              "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
              "      <td>tech</td>\n",
              "      <td>399.txt-tech</td>\n",
              "      <td>Be careful how you code  A new European direct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>400.txt</td>\n",
              "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
              "      <td>tech</td>\n",
              "      <td>400.txt-tech</td>\n",
              "      <td>US cyber security chief resigns  The man makin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>401.txt</td>\n",
              "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
              "      <td>tech</td>\n",
              "      <td>401.txt-tech</td>\n",
              "      <td>Losing yourself in online gaming  Online role ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2225 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     File_Name  ...                                   Content_Parsed_1\n",
              "0      001.txt  ...  Ad sales boost Time Warner profit  Quarterly p...\n",
              "1      002.txt  ...  Dollar gains on Greenspan speech  The dollar h...\n",
              "2      003.txt  ...  Yukos unit buyer faces loan claim  The owners ...\n",
              "3      004.txt  ...  High fuel prices hit BA's profits  British Air...\n",
              "4      005.txt  ...  Pernod takeover talk lifts Domecq  Shares in U...\n",
              "...        ...  ...                                                ...\n",
              "2220   397.txt  ...  BT program to beat dialler scams  BT is introd...\n",
              "2221   398.txt  ...  Spam e-mails tempt net shoppers  Computer user...\n",
              "2222   399.txt  ...  Be careful how you code  A new European direct...\n",
              "2223   400.txt  ...  US cyber security chief resigns  The man makin...\n",
              "2224   401.txt  ...  Losing yourself in online gaming  Online role ...\n",
              "\n",
              "[2225 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "3jLT3iFwFxxC",
        "outputId": "eae771d6-ece3-4a60-c85b-0c783e17c760"
      },
      "source": [
        "df.loc[1]['Content']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman\\'s taking a much more sanguine view on the current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\\n\\nWorries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged to the dollar and the US currency\\'s sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "YHOL1n68F0cw",
        "outputId": "241cf2d0-7879-40ad-87f5-cf29f328e17e"
      },
      "source": [
        "df.loc[1]['Content_Parsed_1']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dollar gains on Greenspan speech  The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman\\'s taking a much more sanguine view on the current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"  Worries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged to the dollar and the US currency\\'s sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW8oNdfiGLIu"
      },
      "source": [
        "# \" уберем ковычки в тексте\n",
        "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJaMymBFx9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8c6a0546-c719-4820-c5e3-86b89e505a16"
      },
      "source": [
        "# приведем весь текст к одному регистру\n",
        "df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower() #upper()\n",
        "\n",
        "df.loc[1]['Content_Parsed_2']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"dollar gains on greenspan speech  the dollar has hit its highest level against the euro in almost three months after the federal reserve head said the us trade deficit is set to stabilise.  and alan greenspan highlighted the us government's willingness to curb spending and rising household savings as factors which may help to reduce it. in late trading in new york, the dollar reached $1.2871 against the euro, from $1.2974 on thursday. market concerns about the deficit has hit the greenback in recent months. on friday, federal reserve chairman mr greenspan's speech in london ahead of the meeting of g7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected us jobs data. i think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time, said robert sinche, head of currency strategy at bank of america in new york. he's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.  worries about the deficit concerns about china do, however, remain. china's currency remains pegged to the dollar and the us currency's sharp falls in recent months have therefore made chinese export prices highly competitive. but calls for a shift in beijing's policy have fallen on deaf ears, despite recent comments in a major chinese newspaper that the time is ripe for a loosening of the peg. the g7 meeting is thought unlikely to produce any meaningful movement in chinese policy. in the meantime, the us federal reserve's decision on 2 february to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with european rates. the half-point window, some believe, could be enough to keep us assets looking more attractive, and could help prop up the dollar. the recent falls have partly been the result of big budget deficits, as well as the us's yawning current account gap, both of which need to be funded by the buying of us bonds and assets by foreign firms and governments. the white house will announce its budget on monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\""
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yp7EOuCGkGv",
        "outputId": "f67c874a-90ea-45a1-ef43-41390e45221b"
      },
      "source": [
        "list(\"?:!.,;\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['?', ':', '!', '.', ',', ';']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYXb851FGfVX"
      },
      "source": [
        "# в тексте присутвуют много знаков пунктуации, которые не свидетельсвуют о теме текста\n",
        "# но если бы мы проводили анализ тональности то это могло быть важным - почему?\n",
        "# что делать с пунктуацией?\n",
        "\n",
        "punctuation_signs = list(\"?:!.,;\")\n",
        "df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
        "\n",
        "for punct_sign in punctuation_signs:\n",
        "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "T_tsnfAqH93W",
        "outputId": "139c8cd3-f66b-42e0-8e6f-47d474771386"
      },
      "source": [
        "df.loc[1]['Content_Parsed_2']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"dollar gains on greenspan speech  the dollar has hit its highest level against the euro in almost three months after the federal reserve head said the us trade deficit is set to stabilise.  and alan greenspan highlighted the us government's willingness to curb spending and rising household savings as factors which may help to reduce it. in late trading in new york, the dollar reached $1.2871 against the euro, from $1.2974 on thursday. market concerns about the deficit has hit the greenback in recent months. on friday, federal reserve chairman mr greenspan's speech in london ahead of the meeting of g7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected us jobs data. i think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time, said robert sinche, head of currency strategy at bank of america in new york. he's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.  worries about the deficit concerns about china do, however, remain. china's currency remains pegged to the dollar and the us currency's sharp falls in recent months have therefore made chinese export prices highly competitive. but calls for a shift in beijing's policy have fallen on deaf ears, despite recent comments in a major chinese newspaper that the time is ripe for a loosening of the peg. the g7 meeting is thought unlikely to produce any meaningful movement in chinese policy. in the meantime, the us federal reserve's decision on 2 february to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with european rates. the half-point window, some believe, could be enough to keep us assets looking more attractive, and could help prop up the dollar. the recent falls have partly been the result of big budget deficits, as well as the us's yawning current account gap, both of which need to be funded by the buying of us bonds and assets by foreign firms and governments. the white house will announce its budget on monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\""
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "LPKE28s4Hy0I",
        "outputId": "27ebfba7-ac19-4f61-91a9-a5e817ba4feb"
      },
      "source": [
        "df.loc[1]['Content_Parsed_3']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"dollar gains on greenspan speech  the dollar has hit its highest level against the euro in almost three months after the federal reserve head said the us trade deficit is set to stabilise  and alan greenspan highlighted the us government's willingness to curb spending and rising household savings as factors which may help to reduce it in late trading in new york the dollar reached $12871 against the euro from $12974 on thursday market concerns about the deficit has hit the greenback in recent months on friday federal reserve chairman mr greenspan's speech in london ahead of the meeting of g7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected us jobs data i think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time said robert sinche head of currency strategy at bank of america in new york he's taking a longer-term view laying out a set of conditions under which the current account deficit can improve this year and next  worries about the deficit concerns about china do however remain china's currency remains pegged to the dollar and the us currency's sharp falls in recent months have therefore made chinese export prices highly competitive but calls for a shift in beijing's policy have fallen on deaf ears despite recent comments in a major chinese newspaper that the time is ripe for a loosening of the peg the g7 meeting is thought unlikely to produce any meaningful movement in chinese policy in the meantime the us federal reserve's decision on 2 february to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with european rates the half-point window some believe could be enough to keep us assets looking more attractive and could help prop up the dollar the recent falls have partly been the result of big budget deficits as well as the us's yawning current account gap both of which need to be funded by the buying of us bonds and assets by foreign firms and governments the white house will announce its budget on monday and many commentators believe the deficit will remain at close to half a trillion dollars\""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgCeC7wHTS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b534379c-16f2-4d66-d631-c1bf14ec6f06"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "\n",
        "# Удаление знаков пунктуации из текста\n",
        "def remove_punct(text):\n",
        "    table = {33: ' ', 34: ' ', 35: ' ', 36: ' ', 37: ' ', 38: ' ', 39: ' ', 40: ' ',\n",
        "             41: ' ', 42: ' ', 43: ' ', 44: ' ', 45: ' ', 46: ' ', 47: ' ', 58: ' ',\n",
        "             59: ' ', 60: ' ', 61: ' ', 62: ' ', 63: ' ', 64: ' ', 91: ' ', 92: ' ',\n",
        "             93: ' ', 94: ' ', 95: ' ', 96: ' ', 123: ' ', 124: ' ', 125: ' ', 126: ' '}\n",
        "    return text.translate(table)\n",
        "\n",
        "df['Content_Parsed_3'] = df['Content_Parsed_3'].map(lambda x: remove_punct(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3X3R_skM3-D"
      },
      "source": [
        "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIJ0ctIYKFeB"
      },
      "source": [
        "## Токенезация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBtYhw5WKJb1"
      },
      "source": [
        "**Токенизация** – это процесс разбиения текста на более мелкие части. В библиотеку spaCy уже встроен конвейер (pipeline), который начинает свою работу по обработке текста с токенизации. В этом руководстве мы разделим текст на отдельные слова. Загрузим пример и проведем разбиение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRGCkIuYKgPh",
        "outputId": "faca0a79-9ff8-415b-d482-681d1b13b41a"
      },
      "source": [
        "nltk.download('punkt')\n",
        "print(\"------------------------------------------------------------\")\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "------------------------------------------------------------\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de5hLipsKKHD",
        "outputId": "698c7b2d-f963-4737-b245-9fd5d38349f0"
      },
      "source": [
        "import nltk\n",
        "\n",
        "sentence_data = \"The First sentence is about Python. The Second: about Django. You can learn Python,Django and Data Ananlysis here. \"\n",
        "nltk_tokens = nltk.sent_tokenize(sentence_data)\n",
        "print(nltk_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The First sentence is about Python.', 'The Second: about Django.', 'You can learn Python,Django and Data Ananlysis here.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlN18HleKkXf",
        "outputId": "26cbf7d9-78dc-4af3-d12f-e63f53b2db1c"
      },
      "source": [
        "import nltk\n",
        "\n",
        "word_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\"\n",
        "nltk_tokens = nltk.word_tokenize(word_data)\n",
        "print(nltk_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['It', 'originated', 'from', 'the', 'idea', 'that', 'there', 'are', 'readers', 'who', 'prefer', 'learning', 'new', 'skills', 'from', 'the', 'comforts', 'of', 'their', 'drawing', 'rooms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nFRLpcRIr9E"
      },
      "source": [
        "## Стеммнг и лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bPwt41qIvXY"
      },
      "source": [
        "Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме.\n",
        "\n",
        "**Стемминг** – это грубый эвристический процесс, который отрезает «лишнее» от корня слов, часто это приводит к потере словообразовательных суффиксов.\n",
        "\n",
        "**Лемматизация** – это более тонкий процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме – лемме.\n",
        "\n",
        "Отличие в том, что стеммер (конкретная реализация алгоритма стемминга – прим.переводчика) действует без знания контекста и, соответственно, не понимает разницу между словами, которые имеют разный смысл в зависимости от части речи. Однако у стеммеров есть и свои преимущества: их проще внедрить и они работают быстрее. Плюс, более низкая «аккуратность» может не иметь значения в некоторых случаях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIIFXmC3Jtd0",
        "outputId": "193ee4a0-8154-45e5-d86b-60e463a7144a"
      },
      "source": [
        "# стемминг\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "e_words= [\"wait\", \"waiting\", \"waited\", \"waits\"]\n",
        "ps = PorterStemmer()\n",
        "for w in e_words:\n",
        "    rootWord=ps.stem(w)\n",
        "    print(rootWord)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait\n",
            "wait\n",
            "wait\n",
            "wait\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJ3jX6rJ4Dt"
      },
      "source": [
        "**Лемматизация** — это алгоритмический процесс нахождения леммы слова в зависимости от его значения. Лемматизация обычно относится к морфологическому анализу слов, целью которого является удаление флективных окончаний. Это помогает в возвращении базовой или словарной формы слова, которое известно как лемма. Метод лемматизации NLTK основан на встроенной морф-функции WorldNet. Предварительная обработка текста включает в себя как основы, так и лемматизации. Многие люди находят два термина запутанными. Некоторые относятся к ним как к одним и тем же, но между ними есть разница. Лемматизация предпочтительнее первой по следующей причине."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TymxPnVJ47s",
        "outputId": "aa60601e-21c3-4237-bb5f-d4b96a8d70fa"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "text = \"studies studying cries cry\"\n",
        "tokenization = nltk.word_tokenize(text)\n",
        "\n",
        "for w in tokenization:\n",
        "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma for studies is study\n",
            "Lemma for studying is studying\n",
            "Lemma for cries is cry\n",
            "Lemma for cry is cry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAdPNLv_L6Hy",
        "outputId": "9e3c8051-f973-41ff-ca1f-8044b6fc3d6f"
      },
      "source": [
        "# !pip install pymorphy2\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "p = morph.parse(\"гуляли\")\n",
        "p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='гуляли', tag=OpencorporaTag('VERB,impf,intr plur,past,indc'), normal_form='гулять', score=1.0, methods_stack=((DictionaryAnalyzer(), 'гуляли', 15, 10),))]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_ZPY28xCMYOe",
        "outputId": "587a9cb5-c4e1-4aea-b3f7-93885171bd21"
      },
      "source": [
        "p[0].normal_form"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'гулять'"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt-1Gx6WI7DW",
        "outputId": "3e7b1230-8c92-4f68-84e9-d87b485e71b9"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "5XP43P1QJNTS",
        "outputId": "af327ad6-6247-4c3a-bf12-94c2340ea370"
      },
      "source": [
        "df.loc[0,'Content_Parsed_4']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ad sales boost time warner profit  quarterly profits at us media giant timewarner jumped 76% to $113bn (â£600m) for the three months to december from $639m year-earlier  the firm which is now one of the biggest investors in google benefited from sales of high-speed internet connections and higher advert sales timewarner said fourth quarter sales rose 2% to $111bn from $109bn its profits were buoyed by one-off gains which offset a profit dip at warner bros and less users for aol  time warner said on friday that it now owns 8% of search-engine google but its own internet business aol had has mixed fortunes it lost 464000 subscribers in the fourth quarter profits were lower than in the preceding three quarters however the company said aol underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high-speed broadband timewarner also has to restate 2000 and 2003 results following a probe by the us securities exchange commission (sec) which is close to concluding  time warner fourth quarter profits were slightly better than analysts' expectations but its film division saw profits slump 27% to $284m helped by box-office flops alexander and catwoman a sharp contrast to year-earlier when the third and final film in the lord of the rings trilogy boosted results for the full-year timewarner posted a profit of $336bn up 27% from its 2003 performance while revenues grew 64% to $4209bn our financial performance was strong meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said for 2005 timewarner is projecting operating earnings growth of around 5% and also expects higher revenue and wider profit margins  timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators it has already offered to pay $300m to settle charges in a deal that is under review by the sec the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at $500m it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it had reported as advertising revenue it will now book the sale of its stake in aol europe as a loss on the value of that stake\""
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_V6vMMKJCp3"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "nrows = len(df)\n",
        "lemmatized_text_list = []\n",
        "\n",
        "for row in range(0, nrows):\n",
        "    \n",
        "    # Create an empty list containing lemmatized words\n",
        "    lemmatized_list = []\n",
        "    \n",
        "    # Save the text and its words into an object\n",
        "    text = df.loc[row]['Content_Parsed_4'] # привет гуляли всю ночь - весь текст\n",
        "    text_words = text.split(\" \") # ['привет', 'гуляли', 'всю', 'ночь'] - список слов всего текста\n",
        "\n",
        "    # Iterate through every word to lemmatize\n",
        "    for word in text_words:\n",
        "        word_norm = wordnet_lemmatizer.lemmatize(word, pos=\"v\")\n",
        "        lemmatized_list.append(word_norm) # ['привет', 'гулять', 'все', 'ночь']\n",
        "        \n",
        "    # Join the list\n",
        "    lemmatized_text = \" \".join(lemmatized_list) # привет гулять все ночь\n",
        "    \n",
        "    # Append to the list containing the texts\n",
        "    lemmatized_text_list.append(lemmatized_text)\n",
        "\n",
        "df['Content_Parsed_5'] = lemmatized_text_list"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "SfeWM5-INEV8",
        "outputId": "943351ea-58cb-4aa3-d942-fd93d0cdecfa"
      },
      "source": [
        "df.loc[0,'Content_Parsed_4']\n",
        "# jumped"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ad sales boost time warner profit  quarterly profits at us media giant timewarner jumped 76% to $113bn (â£600m) for the three months to december from $639m year-earlier  the firm which is now one of the biggest investors in google benefited from sales of high-speed internet connections and higher advert sales timewarner said fourth quarter sales rose 2% to $111bn from $109bn its profits were buoyed by one-off gains which offset a profit dip at warner bros and less users for aol  time warner said on friday that it now owns 8% of search-engine google but its own internet business aol had has mixed fortunes it lost 464000 subscribers in the fourth quarter profits were lower than in the preceding three quarters however the company said aol underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high-speed broadband timewarner also has to restate 2000 and 2003 results following a probe by the us securities exchange commission (sec) which is close to concluding  time warner fourth quarter profits were slightly better than analysts' expectations but its film division saw profits slump 27% to $284m helped by box-office flops alexander and catwoman a sharp contrast to year-earlier when the third and final film in the lord of the rings trilogy boosted results for the full-year timewarner posted a profit of $336bn up 27% from its 2003 performance while revenues grew 64% to $4209bn our financial performance was strong meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said for 2005 timewarner is projecting operating earnings growth of around 5% and also expects higher revenue and wider profit margins  timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators it has already offered to pay $300m to settle charges in a deal that is under review by the sec the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at $500m it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it had reported as advertising revenue it will now book the sale of its stake in aol europe as a loss on the value of that stake\""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "g04fomt2M6mR",
        "outputId": "8832ccd3-33b1-4741-997a-aaeffb9ff03b"
      },
      "source": [
        "df.loc[0,'Content_Parsed_5']\n",
        "# jump"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ad sales boost time warner profit  quarterly profit at us media giant timewarner jump 76% to $113bn (â£600m) for the three months to december from $639m year-earlier  the firm which be now one of the biggest investors in google benefit from sales of high-speed internet connections and higher advert sales timewarner say fourth quarter sales rise 2% to $111bn from $109bn its profit be buoy by one-off gain which offset a profit dip at warner bros and less users for aol  time warner say on friday that it now own 8% of search-engine google but its own internet business aol have have mix fortunes it lose 464000 subscribers in the fourth quarter profit be lower than in the precede three quarter however the company say aol underlie profit before exceptional items rise 8% on the back of stronger internet advertise revenues it hop to increase subscribers by offer the online service free to timewarner internet customers and will try to sign up aol exist customers for high-speed broadband timewarner also have to restate 2000 and 2003 result follow a probe by the us securities exchange commission (sec) which be close to conclude  time warner fourth quarter profit be slightly better than analysts' expectations but its film division saw profit slump 27% to $284m help by box-office flop alexander and catwoman a sharp contrast to year-earlier when the third and final film in the lord of the ring trilogy boost result for the full-year timewarner post a profit of $336bn up 27% from its 2003 performance while revenues grow 64% to $4209bn our financial performance be strong meet or exceed all of our full-year objectives and greatly enhance our flexibility chairman and chief executive richard parsons say for 2005 timewarner be project operate earn growth of around 5% and also expect higher revenue and wider profit margins  timewarner be to restate its account as part of efforts to resolve an inquiry into aol by us market regulators it have already offer to pay $300m to settle charge in a deal that be under review by the sec the company say it be unable to estimate the amount it need to set aside for legal reserve which it previously set at $500m it intend to adjust the way it account for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it have report as advertise revenue it will now book the sale of its stake in aol europe as a loss on the value of that stake\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBSTW65NNLzG"
      },
      "source": [
        "# Стоп-слова"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USo8JrMjNPeJ"
      },
      "source": [
        "Стоп-слова – это слова, которые выкидываются из текста до/после обработки текста. Когда мы применяем машинное обучение к текстам, такие слова могут добавить много шума, поэтому необходимо избавляться от нерелевантных слов.\n",
        "\n",
        "Стоп-слова это обычно понимают артикли, междометия, союзы и т.д., которые не несут смысловой нагрузки. При этом надо понимать, что не существует универсального списка стоп-слов, все зависит от конкретного случая.\n",
        "\n",
        "В NLTK есть предустановленный список стоп-слов. Перед первым использованием вам понадобится его скачать: nltk.download(“stopwords”). После скачивания можно импортировать пакет stopwords и посмотреть на сами слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHWJ9h3YNTwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987a546f-eab2-4986-c409-e6a2eb255c9c"
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "# st = ['stop1', 'stop2', ...]\n",
        "\n",
        "# Loading the stop words in english\n",
        "stop_words = list(stopwords.words('english'))\n",
        "stop_words[0:100]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tsAP-bqTv8e"
      },
      "source": [
        "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
        "\n",
        "for stop_word in stop_words:\n",
        "\n",
        "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
        "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "fxVqhoZ0TyTt",
        "outputId": "02caf2c8-bdee-44c6-e3cd-b5059edcaaa7"
      },
      "source": [
        "df.loc[0,'Content_Parsed_5']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ad sales boost time warner profit  quarterly profit at us media giant timewarner jump 76% to $113bn (â£600m) for the three months to december from $639m year-earlier  the firm which be now one of the biggest investors in google benefit from sales of high-speed internet connections and higher advert sales timewarner say fourth quarter sales rise 2% to $111bn from $109bn its profit be buoy by one-off gain which offset a profit dip at warner bros and less users for aol  time warner say on friday that it now own 8% of search-engine google but its own internet business aol have have mix fortunes it lose 464000 subscribers in the fourth quarter profit be lower than in the precede three quarter however the company say aol underlie profit before exceptional items rise 8% on the back of stronger internet advertise revenues it hop to increase subscribers by offer the online service free to timewarner internet customers and will try to sign up aol exist customers for high-speed broadband timewarner also have to restate 2000 and 2003 result follow a probe by the us securities exchange commission (sec) which be close to conclude  time warner fourth quarter profit be slightly better than analysts' expectations but its film division saw profit slump 27% to $284m help by box-office flop alexander and catwoman a sharp contrast to year-earlier when the third and final film in the lord of the ring trilogy boost result for the full-year timewarner post a profit of $336bn up 27% from its 2003 performance while revenues grow 64% to $4209bn our financial performance be strong meet or exceed all of our full-year objectives and greatly enhance our flexibility chairman and chief executive richard parsons say for 2005 timewarner be project operate earn growth of around 5% and also expect higher revenue and wider profit margins  timewarner be to restate its account as part of efforts to resolve an inquiry into aol by us market regulators it have already offer to pay $300m to settle charge in a deal that be under review by the sec the company say it be unable to estimate the amount it need to set aside for legal reserve which it previously set at $500m it intend to adjust the way it account for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it have report as advertise revenue it will now book the sale of its stake in aol europe as a loss on the value of that stake\""
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "cqYdG43cT2qd",
        "outputId": "8ad3a502-6ead-460f-e320-e3e283868c69"
      },
      "source": [
        "df.loc[0,'Content_Parsed_6']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ad sales boost time warner profit  quarterly profit  us media giant timewarner jump 76%  $113bn (â£600m)   three months  december  $639m year-earlier   firm    one   biggest investors  google benefit  sales  high-speed internet connections  higher advert sales timewarner say fourth quarter sales rise 2%  $111bn  $109bn  profit  buoy  one- gain  offset  profit dip  warner bros  less users  aol  time warner say  friday     8%  search-engine google    internet business aol   mix fortunes  lose 464000 subscribers   fourth quarter profit  lower    precede three quarter however  company say aol underlie profit  exceptional items rise 8%   back  stronger internet advertise revenues  hop  increase subscribers  offer  online service free  timewarner internet customers   try  sign  aol exist customers  high-speed broadband timewarner also   restate 2000  2003 result follow  probe   us securities exchange commission (sec)   close  conclude  time warner fourth quarter profit  slightly better  analysts' expectations   film division saw profit slump 27%  $284m help  box-office flop alexander  catwoman  sharp contrast  year-earlier   third  final film   lord   ring trilogy boost result   full-year timewarner post  profit  $336bn  27%   2003 performance  revenues grow 64%  $4209bn  financial performance  strong meet  exceed    full-year objectives  greatly enhance  flexibility chairman  chief executive richard parsons say  2005 timewarner  project operate earn growth  around 5%  also expect higher revenue  wider profit margins  timewarner   restate  account  part  efforts  resolve  inquiry  aol  us market regulators   already offer  pay $300m  settle charge   deal    review   sec  company say   unable  estimate  amount  need  set aside  legal reserve   previously set  $500m  intend  adjust  way  account   deal  german music publisher bertelsmann purchase   stake  aol europe    report  advertise revenue    book  sale   stake  aol europe   loss   value   stake\""
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "C0g0sXeqL_Q1",
        "outputId": "da026c93-b2a2-479f-d54a-23fde0d4854d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Name</th>\n",
              "      <th>Content</th>\n",
              "      <th>Category</th>\n",
              "      <th>Complete_Filename</th>\n",
              "      <th>Content_Parsed_1</th>\n",
              "      <th>Content_Parsed_2</th>\n",
              "      <th>Content_Parsed_3</th>\n",
              "      <th>Content_Parsed_4</th>\n",
              "      <th>Content_Parsed_5</th>\n",
              "      <th>Content_Parsed_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.txt</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "      <td>001.txt-business</td>\n",
              "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.txt</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "      <td>002.txt-business</td>\n",
              "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
              "      <td>dollar gains on greenspan speech  the dollar h...</td>\n",
              "      <td>dollar gains on greenspan speech  the dollar h...</td>\n",
              "      <td>dollar gains on greenspan speech  the dollar h...</td>\n",
              "      <td>dollar gain on greenspan speech  the dollar ha...</td>\n",
              "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.txt</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>business</td>\n",
              "      <td>003.txt-business</td>\n",
              "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
              "      <td>yukos unit buyer faces loan claim  the owners ...</td>\n",
              "      <td>yukos unit buyer faces loan claim  the owners ...</td>\n",
              "      <td>yukos unit buyer faces loan claim  the owners ...</td>\n",
              "      <td>yukos unit buyer face loan claim  the owners o...</td>\n",
              "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.txt</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>business</td>\n",
              "      <td>004.txt-business</td>\n",
              "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
              "      <td>high fuel prices hit ba's profits  british air...</td>\n",
              "      <td>high fuel prices hit ba's profits  british air...</td>\n",
              "      <td>high fuel prices hit ba profits  british airwa...</td>\n",
              "      <td>high fuel price hit ba profit  british airways...</td>\n",
              "      <td>high fuel price hit ba profit  british airways...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.txt</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>business</td>\n",
              "      <td>005.txt-business</td>\n",
              "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
              "      <td>pernod takeover talk lifts domecq  shares in u...</td>\n",
              "      <td>pernod takeover talk lifts domecq  shares in u...</td>\n",
              "      <td>pernod takeover talk lifts domecq  shares in u...</td>\n",
              "      <td>pernod takeover talk lift domecq  share in uk ...</td>\n",
              "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  File_Name  ...                                   Content_Parsed_6\n",
              "0   001.txt  ...  ad sales boost time warner profit  quarterly p...\n",
              "1   002.txt  ...  dollar gain  greenspan speech   dollar  hit  h...\n",
              "2   003.txt  ...  yukos unit buyer face loan claim   owners  emb...\n",
              "3   004.txt  ...  high fuel price hit ba profit  british airways...\n",
              "4   005.txt  ...  pernod takeover talk lift domecq  share  uk dr...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dvr_3D9T-Jl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4c6eff39-6b9f-4128-9b17-5ed8a221b09c"
      },
      "source": [
        "list_columns = [\"Category\", \"Content\", \"Content_Parsed\"]\n",
        "# df = df[list_columns]\n",
        "\n",
        "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n",
        "df = df[list_columns]\n",
        "df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Content</th>\n",
              "      <th>Content_Parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>high fuel price hit ba profit  british airways...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Category  ...                                     Content_Parsed\n",
              "0  business  ...  ad sales boost time warner profit  quarterly p...\n",
              "1  business  ...  dollar gain  greenspan speech   dollar  hit  h...\n",
              "2  business  ...  yukos unit buyer face loan claim   owners  emb...\n",
              "3  business  ...  high fuel price hit ba profit  british airways...\n",
              "4  business  ...  pernod takeover talk lift domecq  share  uk dr...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_U8pTtDUF1N"
      },
      "source": [
        "# Подготовка данных для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpbJjEyzUOPU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "jon4iBcaUQHl",
        "outputId": "d16be07b-b55d-4442-ee33-30cee0929fb2"
      },
      "source": [
        "category_codes = {\n",
        "    'business': 0,\n",
        "    'entertainment': 1,\n",
        "    'politics': 2,\n",
        "    'sport': 3,\n",
        "    'tech': 4\n",
        "}\n",
        "\n",
        "df['Category_Code'] = df['Category']\n",
        "df = df.replace({'Category_Code':category_codes})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Content</th>\n",
              "      <th>Content_Parsed</th>\n",
              "      <th>Category_Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>high fuel price hit ba profit  british airways...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Category  ... Category_Code\n",
              "0  business  ...             0\n",
              "1  business  ...             0\n",
              "2  business  ...             0\n",
              "3  business  ...             0\n",
              "4  business  ...             0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1flYxyqUYXL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
        "                                                    df['Category_Code'], \n",
        "                                                    test_size=0.15, \n",
        "                                                    random_state=8)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_YGPMNSUkfx"
      },
      "source": [
        "# Векторизация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrI4eUyCUpjp"
      },
      "source": [
        "Text representation\n",
        "We have various options:\n",
        "\n",
        "- Count Vectors as features\n",
        "- TF-IDF Vectors as features\n",
        "- Word Embeddings as features\n",
        "- Text / NLP based features\n",
        "- Topic Models as features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFi0RbdaUu71"
      },
      "source": [
        "We'll use TF-IDF Vectors as features.\n",
        "\n",
        "We have to define the different parameters:\n",
        "\n",
        "- ngram_range: We want to consider both unigrams and bigrams.\n",
        "- max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
        "- min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
        "- max_features: If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "\n",
        "See TfidfVectorizer? for further detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FgXDNycUoWP",
        "outputId": "e78bb428-e531-4225-a88e-1f0fa887f7c4"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "ngram_range = (1,2)\n",
        "# словные\n",
        "# униграммы, биграммы\n",
        "\n",
        "min_df = 10\n",
        "max_df = 1.\n",
        "max_features = 300\n",
        "\n",
        "tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                        ngram_range=ngram_range,\n",
        "                        stop_words=None,\n",
        "                        lowercase=False,\n",
        "                        max_df=max_df,\n",
        "                        min_df=min_df,\n",
        "                        max_features=max_features,\n",
        "                        norm='l2',\n",
        "                        sublinear_tf=True)\n",
        "                        \n",
        "features_train = tfidf.fit_transform(X_train).toarray() # fit()-обучение transfrom()-применение\n",
        "labels_train = y_train\n",
        "print(features_train.shape)\n",
        "\n",
        "features_test = tfidf.transform(X_test).toarray()\n",
        "labels_test = y_test\n",
        "print(features_test.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1891, 300)\n",
            "(334, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlIOozBNXqbS",
        "outputId": "616e9272-c366-4736-aa6d-77e2c2636339"
      },
      "source": [
        "feature_names = tfidf.get_feature_names()\n",
        "print(\"Feature names\", feature_names)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names ['10', '2003', '2004', '2005', 'able', 'accord', 'act', 'action', 'add', 'allow', 'already', 'also', 'although', 'announce', 'another', 'around', 'ask', 'attack', 'award', 'away', 'back', 'bank', 'bbc', 'beat', 'become', 'begin', 'believe', 'best', 'better', 'big', 'biggest', 'bill', 'blair', 'book', 'break', 'bring', 'britain', 'british', 'brown', 'build', 'business', 'buy', 'call', 'campaign', 'case', 'chance', 'change', 'charge', 'chief', 'china', 'claim', 'close', 'club', 'come', 'company', 'computer', 'concern', 'continue', 'control', 'cost', 'could', 'countries', 'country', 'court', 'create', 'cut', 'data', 'day', 'deal', 'decision', 'demand', 'despite', 'digital', 'director', 'drive', 'earlier', 'economic', 'economy', 'election', 'end', 'england', 'eu', 'europe', 'european', 'even', 'every', 'executive', 'expect', 'face', 'fail', 'fall', 'far', 'figure', 'file', 'film', 'final', 'find', 'firm', 'first', 'five', 'follow', 'force', 'foreign', 'former', 'four', 'france', 'future', 'game', 'general', 'get', 'give', 'go', 'good', 'government', 'great', 'group', 'grow', 'growth', 'half', 'hard', 'head', 'help', 'high', 'hit', 'hold', 'home', 'hop', 'house', 'howard', 'however', 'include', 'increase', 'industry', 'information', 'interest', 'international', 'internet', 'ireland', 'issue', 'job', 'keep', 'know', 'labour', 'last', 'last year', 'later', 'launch', 'law', 'lead', 'leave', 'legal', 'let', 'level', 'life', 'like', 'likely', 'line', 'list', 'live', 'london', 'long', 'look', 'lord', 'lose', 'lot', 'mail', 'make', 'many', 'market', 'match', 'may', 'mean', 'media', 'meet', 'million', 'minister', 'mobile', 'money', 'month', 'months', 'move', 'mr', 'mr blair', 'much', 'music', 'name', 'national', 'nations', 'need', 'net', 'network', 'new', 'news', 'next', 'number', 'offer', 'office', 'old', 'one', 'online', 'open', 'part', 'party', 'pay', 'people', 'phone', 'place', 'plan', 'play', 'player', 'players', 'point', 'power', 'president', 'price', 'prime', 'prime minister', 'program', 'provide', 'public', 'put', 'radio', 'real', 'really', 'record', 'release', 'remain', 'report', 'result', 'return', 'right', 'rise', 'rule', 'run', 'sales', 'say', 'say mr', 'second', 'security', 'see', 'sell', 'send', 'service', 'set', 'share', 'show', 'side', 'sign', 'since', 'six', 'software', 'spend', 'spokesman', 'star', 'start', 'state', 'still', 'support', 'system', 'take', 'talk', 'tax', 'team', 'technology', 'tell', 'tell bbc', 'term', 'test', 'think', 'third', 'three', 'time', 'title', 'top', 'trade', 'try', 'turn', 'tv', 'two', 'uk', 'unite', 'us', 'use', 'users', 'video', 'vote', 'wales', 'want', 'warn', 'way', 'week', 'well', 'win', 'without', 'work', 'world', 'would', 'year', 'year old', 'years']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "C7ct4zpjXHzf",
        "outputId": "7cd2f581-044d-4064-d325-8a6f046860d9"
      },
      "source": [
        "df2 = pd.DataFrame(features_train, columns=feature_names)\n",
        "df2.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>2003</th>\n",
              "      <th>2004</th>\n",
              "      <th>2005</th>\n",
              "      <th>able</th>\n",
              "      <th>accord</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>add</th>\n",
              "      <th>allow</th>\n",
              "      <th>already</th>\n",
              "      <th>also</th>\n",
              "      <th>although</th>\n",
              "      <th>announce</th>\n",
              "      <th>another</th>\n",
              "      <th>around</th>\n",
              "      <th>ask</th>\n",
              "      <th>attack</th>\n",
              "      <th>award</th>\n",
              "      <th>away</th>\n",
              "      <th>back</th>\n",
              "      <th>bank</th>\n",
              "      <th>bbc</th>\n",
              "      <th>beat</th>\n",
              "      <th>become</th>\n",
              "      <th>begin</th>\n",
              "      <th>believe</th>\n",
              "      <th>best</th>\n",
              "      <th>better</th>\n",
              "      <th>big</th>\n",
              "      <th>biggest</th>\n",
              "      <th>bill</th>\n",
              "      <th>blair</th>\n",
              "      <th>book</th>\n",
              "      <th>break</th>\n",
              "      <th>bring</th>\n",
              "      <th>britain</th>\n",
              "      <th>british</th>\n",
              "      <th>brown</th>\n",
              "      <th>build</th>\n",
              "      <th>...</th>\n",
              "      <th>talk</th>\n",
              "      <th>tax</th>\n",
              "      <th>team</th>\n",
              "      <th>technology</th>\n",
              "      <th>tell</th>\n",
              "      <th>tell bbc</th>\n",
              "      <th>term</th>\n",
              "      <th>test</th>\n",
              "      <th>think</th>\n",
              "      <th>third</th>\n",
              "      <th>three</th>\n",
              "      <th>time</th>\n",
              "      <th>title</th>\n",
              "      <th>top</th>\n",
              "      <th>trade</th>\n",
              "      <th>try</th>\n",
              "      <th>turn</th>\n",
              "      <th>tv</th>\n",
              "      <th>two</th>\n",
              "      <th>uk</th>\n",
              "      <th>unite</th>\n",
              "      <th>us</th>\n",
              "      <th>use</th>\n",
              "      <th>users</th>\n",
              "      <th>video</th>\n",
              "      <th>vote</th>\n",
              "      <th>wales</th>\n",
              "      <th>want</th>\n",
              "      <th>warn</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>well</th>\n",
              "      <th>win</th>\n",
              "      <th>without</th>\n",
              "      <th>work</th>\n",
              "      <th>world</th>\n",
              "      <th>would</th>\n",
              "      <th>year</th>\n",
              "      <th>year old</th>\n",
              "      <th>years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081110</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103211</td>\n",
              "      <td>0.199844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.24735</td>\n",
              "      <td>0.111843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091924</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164515</td>\n",
              "      <td>0.109074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056847</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.329047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.114899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.127717</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101666</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216645</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.226852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08218</td>\n",
              "      <td>0.135908</td>\n",
              "      <td>0.060424</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.102259</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104321</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101328</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113597</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060291</td>\n",
              "      <td>0.059050</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.193843</td>\n",
              "      <td>0.279994</td>\n",
              "      <td>0.118175</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084602</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.128748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137579</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119753</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300114</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08869</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.199977</td>\n",
              "      <td>0.108741</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.103972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.107975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121518</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129447</td>\n",
              "      <td>0.175812</td>\n",
              "      <td>0.185173</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099187</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130983</td>\n",
              "      <td>0.078337</td>\n",
              "      <td>0.110326</td>\n",
              "      <td>0.083546</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.057598</td>\n",
              "      <td>0.118387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         10      2003      2004  ...      year  year old     years\n",
              "0  0.000000  0.000000  0.000000  ...  0.000000       0.0  0.000000\n",
              "1  0.000000  0.000000  0.000000  ...  0.000000       0.0  0.000000\n",
              "2  0.102259  0.000000  0.000000  ...  0.059050       0.0  0.000000\n",
              "3  0.000000  0.193843  0.279994  ...  0.178303       0.0  0.000000\n",
              "4  0.000000  0.000000  0.000000  ...  0.118387       0.0  0.160063\n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKFWWxVaVPUA"
      },
      "source": [
        "# Подбор моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL-gtUI5VRNr"
      },
      "source": [
        "После того, как мы построим наши векторы признаков, мы попробуем несколько моделей классификации машинного обучения, чтобы найти, какая из них лучше всего работает с нашими данными. Мы попробуем со следующими моделями:\n",
        "\n",
        "- Random Forest\n",
        "- Support Vector Machine (SVC)\n",
        "- K Nearest Neighbors (KNN)\n",
        "- Multinomial Logistic Regression\n",
        "- Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqtMz2yRYMmk"
      },
      "source": [
        "- как подобрать гиперпараметры модели?\n",
        "- как метрики для оценки модели использовать?\n",
        "- нужна ли нормализация данных?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pclr1irDVr-G",
        "outputId": "b22cf9c1-7083-4a63-d182-041aed9a6d20"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "svc_base = svm.SVC(random_state=8)\n",
        "\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(svc_base.get_params())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'C': 1.0,\n",
            " 'break_ties': False,\n",
            " 'cache_size': 200,\n",
            " 'class_weight': None,\n",
            " 'coef0': 0.0,\n",
            " 'decision_function_shape': 'ovr',\n",
            " 'degree': 3,\n",
            " 'gamma': 'scale',\n",
            " 'kernel': 'rbf',\n",
            " 'max_iter': -1,\n",
            " 'probability': False,\n",
            " 'random_state': 8,\n",
            " 'shrinking': True,\n",
            " 'tol': 0.001,\n",
            " 'verbose': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNzSejtQTKOH",
        "outputId": "67e78a02-4ea8-4234-db0b-723b4f9deeaf"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tvrfUq_TaPz",
        "outputId": "9080d93b-f9e7-4723-b6ec-c3dc5c45bdcd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzFgMOsjVy1C"
      },
      "source": [
        "- C: Penalty parameter C of the error term.\n",
        "- kernel: Specifies the kernel type to be used in the algorithm.\n",
        "- gamma: Kernel coefficient.\n",
        "- degree: Degree of the polynomial kernel function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OftnBjGpYrQU"
      },
      "source": [
        "## Подбор гиперпараметров модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI7N94pgYuCc",
        "outputId": "3bd44dee-680e-4f62-a4a2-6c4f21409b32"
      },
      "source": [
        "# C\n",
        "C = [.0001, .001, .01]\n",
        "\n",
        "# gamma\n",
        "gamma = [.0001, .001, .01, .1, 1, 10, 100]\n",
        "\n",
        "# degree\n",
        "degree = [1, 2, 3, 4, 5]\n",
        "\n",
        "# kernel\n",
        "kernel = ['linear', 'rbf', 'poly']\n",
        "\n",
        "# probability\n",
        "probability = [True]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'C': C,\n",
        "              'kernel': kernel,\n",
        "              'gamma': gamma,\n",
        "              'degree': degree,\n",
        "              'probability': probability\n",
        "             }\n",
        "\n",
        "pprint(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': [0.0001, 0.001, 0.01],\n",
            " 'degree': [1, 2, 3, 4, 5],\n",
            " 'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
            " 'kernel': ['linear', 'rbf', 'poly'],\n",
            " 'probability': [True]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PwtP3XdY2a-",
        "outputId": "4fe8848d-0e95-4c08-83b3-e34c408618ba"
      },
      "source": [
        "# First create the base model to tune\n",
        "svc = svm.SVC(random_state=8)\n",
        "\n",
        "# Definition of the random search\n",
        "random_search = RandomizedSearchCV(estimator=svc,\n",
        "                                   param_distributions=random_grid,\n",
        "                                   n_iter=50,\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3, \n",
        "                                   verbose=1, \n",
        "                                   random_state=8)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(features_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 15.2min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                                 class_weight=None, coef0=0.0,\n",
              "                                 decision_function_shape='ovr', degree=3,\n",
              "                                 gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                                 probability=False, random_state=8,\n",
              "                                 shrinking=True, tol=0.001, verbose=False),\n",
              "                   iid='deprecated', n_iter=50, n_jobs=None,\n",
              "                   param_distributions={'C': [0.0001, 0.001, 0.01],\n",
              "                                        'degree': [1, 2, 3, 4, 5],\n",
              "                                        'gamma': [0.0001, 0.001, 0.01, 0.1, 1,\n",
              "                                                  10, 100],\n",
              "                                        'kernel': ['linear', 'rbf', 'poly'],\n",
              "                                        'probability': [True]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHn9byubY6sX",
        "outputId": "f22ed26c-61a5-438e-e7cd-c2fc50c62b0d"
      },
      "source": [
        "# После перебора гиперпараметров, посмотрим которые лучшие\n",
        "\n",
        "print(\"The best hyperparameters from Random Search are:\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\")\n",
        "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
        "print(random_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best hyperparameters from Random Search are:\n",
            "{'probability': True, 'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
            "\n",
            "The mean accuracy of a model with these hyperparameters is:\n",
            "0.9238497723442256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jb9Sm_ZZNAe"
      },
      "source": [
        "best_svc = random_search.best_estimator_\n",
        "\n",
        "best_svc.fit(features_train, labels_train)\n",
        "\n",
        "best_svc_pred = best_svc.predict(features_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx5ZtGP6ZXPM",
        "outputId": "54609a64-ee76-4e29-ca0a-04f808f4cdfd"
      },
      "source": [
        "# Training accuracy\n",
        "print(\"The training accuracy is: \")\n",
        "print(accuracy_score(labels_train, best_svc.predict(features_train)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is: \n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeR7vvKlZY_i",
        "outputId": "d120bbe6-cadc-48cf-e073-283242d4f692"
      },
      "source": [
        "# Test accuracy\n",
        "print(\"The test accuracy is: \")\n",
        "print(accuracy_score(labels_test, best_svc_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test accuracy is: \n",
            "0.9281437125748503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90gUv6L1dIzX",
        "outputId": "6b050c75-ef59-4e4c-8e88-1d2761c9faf0"
      },
      "source": [
        "base_model = svm.SVC(random_state = 8)\n",
        "base_model.fit(features_train, labels_train)\n",
        "accuracy_score(labels_test, base_model.predict(features_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9491017964071856"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vc91WcgfhXc",
        "outputId": "a4a27cdd-2d62-439f-e2d1-5f5205c71365"
      },
      "source": [
        "best_svc.fit(features_train, labels_train)\n",
        "accuracy_score(labels_test, best_svc.predict(features_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9281437125748503"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    }
  ]
}